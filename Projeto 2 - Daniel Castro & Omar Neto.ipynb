{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Ciência dos Dados - PROJETO 2 - 2019/1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Daniel Castro\n",
    "\n",
    "## Omar Dibo Calixto Afrange Neto\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## 1. Problema\n",
    "\n",
    "O Classificador Naive-Bayes, o qual se baseia no uso do teorema de Bayes, é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser SPAM considerando as palavras em seu conteúdo e, de forma complementar, permite calcular a probabilidade de uma mensagem ser HAM dada as palavras descritas na mensagem.\n",
    "\n",
    "Para realizar o MVP (minimum viable product) do projeto, você precisa programar uma versão do classificador que \"aprende\" o que é uma mensagem SPAM considerando uma base de treinamento e comparar o desempenho dos resultados com uma base de testes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 2. Separação da base de dados em Treinamento e Teste\n",
    "\n",
    "A base de dados deve ser separada em duas partes, aleatoriamente, considerando: \n",
    "    \n",
    "    75% dos dados para a parte Treinamento; e\n",
    "    25% dos dados para a parte Teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dados=pd.read_excel('spamham2019(1).xlsx')\n",
    "x=dados.sample(frac=1)\n",
    "x=x.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "treinamento = x.loc[:5572*0.75,:]\n",
    "teste = x.loc[5572*0.75:,:]\n",
    "\n",
    "treinamento_spam = treinamento[treinamento.Class == \"spam\"]\n",
    "treinamento_ham = treinamento[treinamento.Class == \"ham\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 3. Classificador Naive-Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limpando o DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_treinamento = treinamento[\"Email\"].tolist()\n",
    "lista_treinamento = str(lista_treinamento)\n",
    "lista_treinamento = lista_treinamento.replace(\",\",\"\")\n",
    "lista_treinamento = lista_treinamento.replace(\"'\",\"\")\n",
    "lista_treinamento = lista_treinamento.replace(\"[\",\"\")\n",
    "lista_treinamento = lista_treinamento.replace(\"]\",\"\")\n",
    "lista_treinamento = lista_treinamento.replace(\":\",\"\")\n",
    "lista_treinamento = lista_treinamento.replace(\";\",\"\")\n",
    "lista_treinamento = lista_treinamento.replace(\"_\",\"\")\n",
    "lista_treinamento = lista_treinamento.replace(\"$\",\"\")\n",
    "lista_treinamento = lista_treinamento.replace(\"&\",\"\")\n",
    "lista_treinamento = lista_treinamento.replace(\"(\",\"\")\n",
    "lista_treinamento = lista_treinamento.replace(\")\",\"\")\n",
    "lista_treinamento = lista_treinamento.replace(\".\",\"\")\n",
    "lista_treinamento = lista_treinamento.replace(\"#\",\"\")                                              \n",
    "lista_treinamento = lista_treinamento.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_treinamento_spam = treinamento_spam[\"Email\"].tolist()\n",
    "lista_treinamento_spam = str(lista_treinamento_spam)\n",
    "lista_treinamento_spam = lista_treinamento_spam.replace(\",\",\"\")\n",
    "lista_treinamento_spam = lista_treinamento_spam.replace(\"'\",\"\")\n",
    "lista_treinamento_spam = lista_treinamento_spam.replace(\"[\",\"\")\n",
    "lista_treinamento_spam = lista_treinamento_spam.replace(\"]\",\"\")\n",
    "lista_treinamento_spam = lista_treinamento_spam.replace(\":\",\"\")\n",
    "lista_treinamento_spam = lista_treinamento_spam.replace(\";\",\"\")\n",
    "lista_treinamento_spam = lista_treinamento_spam.replace(\"_\",\"\")\n",
    "lista_treinamento_spam = lista_treinamento_spam.replace(\"$\",\"\")\n",
    "lista_treinamento_spam = lista_treinamento_spam.replace(\"&\",\"\")\n",
    "lista_treinamento_spam = lista_treinamento_spam.replace(\"(\",\"\")\n",
    "lista_treinamento_spam = lista_treinamento_spam.replace(\")\",\"\")\n",
    "lista_treinamento_spam = lista_treinamento_spam.replace(\".\",\"\")\n",
    "lista_treinamento_spam = lista_treinamento_spam.replace(\"#\",\"\")                                              \n",
    "lista_treinamento_spam = lista_treinamento_spam.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_treinamento_ham = treinamento_ham[\"Email\"].tolist()\n",
    "lista_treinamento_ham = str(lista_treinamento_ham)\n",
    "lista_treinamento_ham = lista_treinamento_ham.replace(\",\",\"\")\n",
    "lista_treinamento_ham = lista_treinamento_ham.replace(\"'\",\"\")\n",
    "lista_treinamento_ham = lista_treinamento_ham.replace(\"[\",\"\")\n",
    "lista_treinamento_ham = lista_treinamento_ham.replace(\"]\",\"\")\n",
    "lista_treinamento_ham = lista_treinamento_ham.replace(\":\",\"\")\n",
    "lista_treinamento_ham = lista_treinamento_ham.replace(\";\",\"\")\n",
    "lista_treinamento_ham = lista_treinamento_ham.replace(\"_\",\"\")\n",
    "lista_treinamento_ham = lista_treinamento_ham.replace(\"$\",\"\")\n",
    "lista_treinamento_ham = lista_treinamento_ham.replace(\"&\",\"\")\n",
    "lista_treinamento_ham = lista_treinamento_ham.replace(\"(\",\"\")\n",
    "lista_treinamento_ham = lista_treinamento_ham.replace(\")\",\"\")\n",
    "lista_treinamento_ham = lista_treinamento_ham.replace(\".\",\"\")\n",
    "lista_treinamento_ham = lista_treinamento_ham.replace(\"#\",\"\")                                              \n",
    "lista_treinamento_ham = lista_treinamento_ham.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Propabilidades de Ham e Spam**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem de hams:86.4354066985646%\n",
      "Porcentagem de spams:13.564593301435407%\n"
     ]
    }
   ],
   "source": [
    "numero_ham = treinamento['Email'][treinamento['Class'] == \"ham\"].count() #Contagem do total de hams \n",
    "numero_spam = treinamento['Email'][treinamento['Class'] == \"spam\"].count() #Contagem do total de spams\n",
    "total = numero_ham + numero_spam #Contagem total de mensagens\n",
    "\n",
    "porcentagem_ham= (numero_ham/total) #Probabilidade de hams\n",
    "porcentagem_spam= (numero_spam/total) #Probabilidade de irrelevantes\n",
    "\n",
    "print (\"Porcentagem de hams:{0}%\".format(porcentagem_ham*100))\n",
    "print (\"Porcentagem de spams:{0}%\".format(porcentagem_spam*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Contando o número de vezes que cada palavra aparece**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total\n",
    "palavras_treinamento = {}\n",
    "for palavra in lista_treinamento:\n",
    "    if palavra not in palavras_treinamento:\n",
    "        palavras_treinamento[palavra] = 1\n",
    "    else:\n",
    "        palavras_treinamento[palavra] += 1\n",
    "        \n",
    "        \n",
    "#Spams        \n",
    "palavras_treinamento_spam = {}\n",
    "for palavra in lista_treinamento_spam:\n",
    "    if palavra not in palavras_treinamento_spam:\n",
    "        palavras_treinamento_spam[palavra] = 1\n",
    "    else:\n",
    "        palavras_treinamento_spam[palavra] += 1\n",
    "        \n",
    "        \n",
    "#Hams\n",
    "palavras_treinamento_ham = {}\n",
    "for palavra in lista_treinamento_ham:\n",
    "    if palavra not in palavras_treinamento_ham:\n",
    "        palavras_treinamento_ham[palavra] = 1\n",
    "    else:\n",
    "        palavras_treinamento_ham[palavra] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculando a probabilidade da mensagem ser Ham ou Spam**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificador_mensagem(mensagem, dic1, dic2):\n",
    "    \n",
    "    probabilidade_spam = 0\n",
    "    probabilidade_ham = 0\n",
    "    mensagem_splitada = mensagem.split()\n",
    "    soma_spam = sum(palavras_treinamento_spam.values())\n",
    "    soma_ham = sum(palavras_treinamento_ham.values())\n",
    "    resultado=str()\n",
    "    for palavra in mensagem_splitada:\n",
    "        quantidade_ham = 0\n",
    "        quantidade_spam = 0\n",
    "        if palavra in dic1:\n",
    "            quantidade_ham += palavras_treinamento_ham[palavra]\n",
    "        if palavra in dic2:\n",
    "            quantidade_spam += palavras_treinamento_spam[palavra]\n",
    "        probabilidade_ham = ((quantidade_ham)+1)/(soma_spam + len(palavras_treinamento))\n",
    "        probabilidade_spam = ((quantidade_spam)+1)/(soma_ham + len(palavras_treinamento))\n",
    "    if probabilidade_spam/probabilidade_ham >= 1:\n",
    "        resultado = \"spam\"\n",
    "    elif probabilidade_spam/probabilidade_ham < 1:\n",
    "        resultado = \"ham\"\n",
    "    return resultado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 4. Qualidade do Classificador alterando a base de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.66762383345298 % de acerto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Verificar a porcentagem de acerto do classificador (precisão)\n",
    "classificacao = []\n",
    "for mensagem in teste[\"Email\"]:\n",
    "    classificacao.append(classificador_mensagem(mensagem, palavras_treinamento_ham, palavras_treinamento_spam))\n",
    "\n",
    "teste[\"Classificador\"] = classificacao\n",
    "\n",
    "porcentagem_acerto = teste[\"Email\"][teste[\"Class\"] == teste[\"Classificador\"]].count()\n",
    "print(porcentagem_acerto/len(teste) * 100,\"% de acerto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Classificador de Naive-Bayes desenvolvido por nós, para classificar e-mails, como 'úteis' ou 'spam', apresentou uma qualidade muito boa com 90,67% de acerto, porem isso nos leva, ao mesmo tempo, a desconfiar um pouco do mesmo, uma vez que a base de treinamento utilizada nao era tão ampla, o que poderia ser facilmente resolvido com um aumento da base de dados. Além disso poderíamos melhorar a classificação de relevância gerando uma menor taxa de erros. Se pudessemos implementar essas novas ideias talvez possamos no futuro trabalhar em um projeto mais complexo de reconhecimento de vírus em um computador ou smartphone por exemplo."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
